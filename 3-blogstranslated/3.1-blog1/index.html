<!doctype html><html lang=en class="js csstransforms3d"><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.134.3"><meta name=description content><meta name=author content="thienlh@thienlu.com"><link rel=icon href=https://nguyenleanhquan2005.github.io/AWS_Report/images/favicon.png type=image/png><title>Blog 1 :: Internship Report</title>
<link href=https://nguyenleanhquan2005.github.io/AWS_Report/css/nucleus.css?1765295284 rel=stylesheet><link href=https://nguyenleanhquan2005.github.io/AWS_Report/css/fontawesome-all.min.css?1765295284 rel=stylesheet><link href=https://nguyenleanhquan2005.github.io/AWS_Report/css/hybrid.css?1765295284 rel=stylesheet><link href=https://nguyenleanhquan2005.github.io/AWS_Report/css/featherlight.min.css?1765295284 rel=stylesheet><link href=https://nguyenleanhquan2005.github.io/AWS_Report/css/perfect-scrollbar.min.css?1765295284 rel=stylesheet><link href=https://nguyenleanhquan2005.github.io/AWS_Report/css/auto-complete.css?1765295284 rel=stylesheet><link href=https://nguyenleanhquan2005.github.io/AWS_Report/css/atom-one-dark-reasonable.css?1765295284 rel=stylesheet><link href=https://nguyenleanhquan2005.github.io/AWS_Report/css/theme.css?1765295284 rel=stylesheet><link href=https://nguyenleanhquan2005.github.io/AWS_Report/css/hugo-theme.css?1765295284 rel=stylesheet><link href=https://nguyenleanhquan2005.github.io/AWS_Report/css/theme-workshop.css?1765295284 rel=stylesheet><script src=https://nguyenleanhquan2005.github.io/AWS_Report/js/jquery-3.3.1.min.js?1765295284></script><style>:root #header+#content>#left>#rlblock_left{display:none!important}</style></head><body data-url=https://nguyenleanhquan2005.github.io/AWS_Report/3-blogstranslated/3.1-blog1/><nav id=sidebar class=showVisitedLinks><div id=header-wrapper><div id=header><a id=logo href=https://nguyenleanhquan2005.github.io/AWS_Report/><svg id="Layer_1" data-name="Layer 1" viewBox="0 0 60 30" width="30%"><defs><style>.cls-1{fill:#fff}.cls-2{fill:#f90;fill-rule:evenodd}</style></defs><title>AWS-Logo_White-Color</title><path class="cls-1" d="M14.09 10.85a4.7 4.7.0 00.19 1.48 7.73 7.73.0 00.54 1.19.77.77.0 01.12.38.64.64.0 01-.32.49l-1 .7a.83.83.0 01-.44.15.69.69.0 01-.49-.23 3.8 3.8.0 01-.6-.77q-.25-.42-.51-1a6.14 6.14.0 01-4.89 2.3 4.54 4.54.0 01-3.32-1.19 4.27 4.27.0 01-1.22-3.2 4.28 4.28.0 011.46-3.4A6.06 6.06.0 017.69 6.46a12.47 12.47.0 011.76.13q.92.13 1.91.36V5.73a3.65 3.65.0 00-.79-2.66A3.81 3.81.0 007.86 2.3a7.71 7.71.0 00-1.79.22 12.78 12.78.0 00-1.79.57 4.55 4.55.0 01-.58.22h-.26q-.35.0-.35-.52V2a1.09 1.09.0 01.12-.58 1.2 1.2.0 01.47-.35A10.88 10.88.0 015.77.32 10.19 10.19.0 018.36.0a6 6 0 014.35 1.35 5.49 5.49.0 011.38 4.09zM7.34 13.38a5.36 5.36.0 001.72-.31A3.63 3.63.0 0010.63 12 2.62 2.62.0 0011.19 11a5.63 5.63.0 00.16-1.44v-.7a14.35 14.35.0 00-1.53-.28 12.37 12.37.0 00-1.56-.1 3.84 3.84.0 00-2.47.67A2.34 2.34.0 005 11a2.35 2.35.0 00.61 1.76A2.4 2.4.0 007.34 13.38zm13.35 1.8a1 1 0 01-.64-.16 1.3 1.3.0 01-.35-.65L15.81 1.51a3 3 0 01-.15-.67.36.36.0 01.41-.41H17.7a1 1 0 01.65.16 1.4 1.4.0 01.33.65l2.79 11 2.59-11A1.17 1.17.0 0124.39.6a1.1 1.1.0 01.67-.16H26.4a1.1 1.1.0 01.67.16 1.17 1.17.0 01.32.65L30 12.39 32.88 1.25A1.39 1.39.0 0133.22.6a1 1 0 01.65-.16h1.54a.36.36.0 01.41.41 1.36 1.36.0 010 .26 3.64 3.64.0 01-.12.41l-4 12.86a1.3 1.3.0 01-.35.65 1 1 0 01-.64.16H29.25a1 1 0 01-.67-.17 1.26 1.26.0 01-.32-.67L25.67 3.64l-2.56 10.7a1.26 1.26.0 01-.32.67 1 1 0 01-.67.17zm21.36.44a11.28 11.28.0 01-2.56-.29 7.44 7.44.0 01-1.92-.67 1 1 0 01-.61-.93v-.84q0-.52.38-.52a.9.9.0 01.31.06l.42.17a8.77 8.77.0 001.83.58 9.78 9.78.0 002 .2 4.48 4.48.0 002.43-.55 1.76 1.76.0 00.86-1.57 1.61 1.61.0 00-.45-1.16A4.29 4.29.0 0043 9.22l-2.41-.76A5.15 5.15.0 0138 6.78a3.94 3.94.0 01-.83-2.41 3.7 3.7.0 01.45-1.85 4.47 4.47.0 011.19-1.37 5.27 5.27.0 011.7-.86A7.4 7.4.0 0142.6.0a8.87 8.87.0 011.12.07q.57.07 1.08.19t.95.26a4.27 4.27.0 01.7.29 1.59 1.59.0 01.49.41.94.94.0 01.15.55v.79q0 .52-.38.52a1.76 1.76.0 01-.64-.2 7.74 7.74.0 00-3.2-.64 4.37 4.37.0 00-2.21.47 1.6 1.6.0 00-.79 1.48 1.58 1.58.0 00.49 1.18 4.94 4.94.0 001.83.92L44.55 7a5.08 5.08.0 012.57 1.6A3.76 3.76.0 0147.9 11a4.21 4.21.0 01-.44 1.93 4.4 4.4.0 01-1.21 1.47 5.43 5.43.0 01-1.85.93A8.25 8.25.0 0142.05 15.62z"/><path class="cls-2" d="M45.19 23.81C39.72 27.85 31.78 30 25 30A36.64 36.64.0 01.22 20.57c-.51-.46-.06-1.09.56-.74A49.78 49.78.0 0025.53 26.4 49.23 49.23.0 0044.4 22.53C45.32 22.14 46.1 23.14 45.19 23.81z"/><path class="cls-2" d="M47.47 21.21c-.7-.9-4.63-.42-6.39-.21-.53.06-.62-.4-.14-.74 3.13-2.2 8.27-1.57 8.86-.83s-.16 5.89-3.09 8.35c-.45.38-.88.18-.68-.32C46.69 25.8 48.17 22.11 47.47 21.21z"/></svg></a></div><div class=searchbox><label for=search-by><i class="fas fa-search"></i></label>
<input data-search-input id=search-by type=search placeholder=Search...>
<span data-search-clear><i class="fas fa-times"></i></span></div><script type=text/javascript src=https://nguyenleanhquan2005.github.io/AWS_Report/js/lunr.min.js?1765295284></script><script type=text/javascript src=https://nguyenleanhquan2005.github.io/AWS_Report/js/auto-complete.js?1765295284></script><script type=text/javascript>var baseurl="https://nguyenleanhquan2005.github.io/AWS_Report/"</script><script type=text/javascript src=https://nguyenleanhquan2005.github.io/AWS_Report/js/search.js?1765295284></script></div><div class=highlightable><ul class=topics><li data-nav-id=/1-worklog/ title=Worklog class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/1-worklog/><b>1. </b>Worklog
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/1-worklog/1.1-week1/ title="Week 1 Worklog" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/1-worklog/1.1-week1/><b>1.1. </b>Week 1 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.2-week2/ title="Week 2 Worklog" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/1-worklog/1.2-week2/><b>1.2. </b>Week 2 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.3-week3/ title="Week 3 Worklog" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/1-worklog/1.3-week3/><b>1.3. </b>Week 3 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.4-week4/ title="Week 4 Worklog" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/1-worklog/1.4-week4/><b>1.4. </b>Week 4 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.5-week5/ title="Week 5 Worklog" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/1-worklog/1.5-week5/><b>1.5. </b>Week 5 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.6-week6/ title="Week 6 Worklog" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/1-worklog/1.6-week6/><b>1.6. </b>Week 6 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.7-week7/ title="Week 7 Worklog" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/1-worklog/1.7-week7/><b>1.7. </b>Week 7 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.8-week8/ title="Week 8 Worklog" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/1-worklog/1.8-week8/><b>1.8. </b>Week 8 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.9-week9/ title="Week 9 Worklog" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/1-worklog/1.9-week9/><b>1.9. </b>Week 9 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.10-week10/ title="Week 10 Worklog" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/1-worklog/1.10-week10/><b>1.10. </b>Week 10 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.11-week11/ title="Week 11 Worklog" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/1-worklog/1.11-week11/><b>1.11. </b>Week 11 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.12-week12/ title="Week 12 Worklog" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/1-worklog/1.12-week12/><b>1.12. </b>Week 12 Worklog
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/2-proposal/ title=Proposal class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/2-proposal/><b>2. </b>Proposal
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/ title="Translated Blogs" class="dd-item
parent"><a href=https://nguyenleanhquan2005.github.io/AWS_Report/3-blogstranslated/><b>3. </b>Translated Blogs
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/3-blogstranslated/3.1-blog1/ title="Blog 1" class="dd-item
active"><a href=https://nguyenleanhquan2005.github.io/AWS_Report/3-blogstranslated/3.1-blog1/><b>3.1. </b>Blog 1
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/3.2-blog2/ title="Blog 2" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/3-blogstranslated/3.2-blog2/><b>3.2. </b>Blog 2
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/3.3-blog3/ title="Blog 3" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/3-blogstranslated/3.3-blog3/><b>3.3. </b>Blog 3
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/4-eventparticipated/ title="Events Participated" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/4-eventparticipated/><b>4. </b>Events Participated
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/4-eventparticipated/4.1-event1/ title="Event 1: AI-Driven Development Life Cycle: Reimagining Software Engineering" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/4-eventparticipated/4.1-event1/><b>4.1. </b>Event 1: AI-Driven Development Life Cycle: Reimagining Software Engineering
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.2-event2/ title="Event 1: AI/ML/GenAI on AWS Workshop" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/4-eventparticipated/4.2-event2/><b>4.1. </b>Event 1: AI/ML/GenAI on AWS Workshop
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.3-event3/ title="Event 2: AWS DevOps Full-Day Workshop" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/4-eventparticipated/4.3-event3/><b>4.2. </b>Event 2: AWS DevOps Full-Day Workshop
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/5-workshop/ title=Workshop class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/5-workshop/><b>5. </b>Workshop
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/5-workshop/5.1-workshop-overview/ title="Module 1: Prerequisites" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/5-workshop/5.1-workshop-overview/><b>5.1. </b>Module 1: Prerequisites
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.2-prerequiste/ title="Module 2: Building Knowledge Base" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/5-workshop/5.2-prerequiste/><b>5.2. </b>Module 2: Building Knowledge Base
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.3-connect-data/ title="Module 3: Developing Serverless Backend" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/5-workshop/5.3-connect-data/><b>5.3. </b>Module 3: Developing Serverless Backend
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.4-create-visuals/ title="Module 4: API & Security" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/5-workshop/5.4-create-visuals/><b>5.4. </b>Module 4: API & Security
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.5-public-dashboard/ title="Module 5: Frontend Integration & Testing" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/5-workshop/5.5-public-dashboard/><b>5.5. </b>Module 5: Frontend Integration & Testing
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.6-cleanup/ title="Module 6: Clean Up Resources" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/5-workshop/5.6-cleanup/><b>5.6. </b>Module 6: Clean Up Resources
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/6-self-evaluation/ title=Self-Assessment class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/6-self-evaluation/><b>6. </b>Self-Assessment
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/7-feedback/ title="Feedback & Suggestions" class=dd-item><a href=https://nguyenleanhquan2005.github.io/AWS_Report/7-feedback/><b>7. </b>Feedback & Suggestions
<i class="fas fa-check read-icon"></i></a></li></ul><section id=shortcuts><h3>More</h3><ul><li><a class=padding href=https://www.facebook.com/groups/awsstudygroupfcj/><i class='fab fa-facebook'></i> AWS Study Group</a></li></ul></section><section id=prefooter><hr><ul><li><a class=padding><i class="fas fa-language fa-fw"></i><div class=select-style><select id=select-language onchange="location=this.value"><option id=en value=https://nguyenleanhquan2005.github.io/AWS_Report/3-blogstranslated/3.1-blog1/ selected>English</option><option id=vi value=https://nguyenleanhquan2005.github.io/AWS_Report/vi/3-blogstranslated/3.1-blog1/>Tiếng Việt</option></select><svg id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" width="255" height="255" viewBox="0 0 255 255" style="enable-background:new 0 0 255 255"><g><g id="arrow-drop-down"><polygon points="0,63.75 127.5,191.25 255,63.75"/></g></g></svg></div></a></li><li><a class=padding href=# data-clear-history-toggle><i class="fas fa-history fa-fw"></i> Clear History</a></li></ul></section><section id=footer><left><b>Workshop</b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7920860&style=0038&nbdigits=9&type=page&initCount=0" title=Migrate alt="web counter" border=0></a><br><b><a href=https://cloudjourney.awsstudygroup.com/>Cloud Journey</a></b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7830807&style=0038&nbdigits=9&type=page&initCount=0" title="Total CLoud Journey" alt="web counter" border=0>
</left><left><br><br><b>Last Updated</b><br><i><span id=lastUpdated style=color:orange></span>
</i><script>const today=new Date,formattedDate=today.toLocaleDateString("en-GB");document.getElementById("lastUpdated").textContent=formattedDate</script></left><left><br><br><b>Team</b><br><i><a href=https://www.facebook.com/groups/660548818043427 style=color:orange>First Cloud Journey</a><br></i></left><script async defer src=https://buttons.github.io/buttons.js></script></section></div></nav><section id=body><div id=overlay></div><div class="padding highlightable"><div><div id=top-bar><div id=breadcrumbs itemscope itemtype=http://data-vocabulary.org/Breadcrumb><span id=sidebar-toggle-span><a href=# id=sidebar-toggle data-sidebar-toggle><i class="fas fa-bars"></i>
</a></span><span id=toc-menu><i class="fas fa-list-alt"></i></span>
<span class=links><a href=https://nguyenleanhquan2005.github.io/AWS_Report/>Internship Report</a> > <a href=https://nguyenleanhquan2005.github.io/AWS_Report/3-blogstranslated/>Translated Blogs</a> > Blog 1</span></div><div class=progress><div class=wrapper><nav id=TableOfContents><ul><li><a href=#artificial-intelligencehttpsawsamazoncomblogsmachine-learning><a href=https://aws.amazon.com/blogs/machine-learning/>Artificial Intelligence</a></a></li></ul><ul><li><a href=#solution-overview><strong>Solution overview</strong></a></li><li><a href=#prerequisites><strong>Prerequisites</strong></a></li><li><a href=#structure-prompts-that-maximize-control><strong>Structure prompts that maximize control</strong></a><ul><li><a href=#choose-the-right-prompt-type-for-your-use-case><strong>Choose the right prompt type for your use case</strong></a></li><li><a href=#build-modular-prompts><strong>Build modular prompts</strong></a></li><li><a href=#use-negative-prompts-for-polished-output><strong>Use negative prompts for polished output</strong></a></li><li><a href=#emphasize-or-suppress-elements-with-prompt-weighting><strong>Emphasize or suppress elements with prompt weighting</strong></a></li></ul></li><li><a href=#giving-specific-stylistic-guidance><strong>Giving specific stylistic guidance</strong></a><ul><li><a href=#style-tag-layering-known-aesthetic-labels-that-align-with-brand-identity><strong>Style tag layering: Known aesthetic labels that align with brand identity</strong></a></li><li><a href=#invoke-a-named-style-as-a-reference><strong>Invoke a named style as a reference</strong></a></li><li><a href=#use-reference-images-to-guide-style><strong>Use reference images to guide style</strong></a></li><li><a href=#create-the-right-mood-with-lighting-control><strong>Create the right mood with lighting control</strong></a></li><li><a href=#build-intent-with-posing-and-framing-terms><strong>Build intent with posing and framing terms</strong></a></li><li><a href=#example-putting-it-all-together><strong>Example: Putting it all together</strong></a></li></ul></li><li><a href=#best-practices-and-troubleshooting><strong>Best practices and troubleshooting</strong></a></li><li><a href=#conclusion><strong>Conclusion</strong></a><ul><li><a href=#about-the-authors><strong>About the authors</strong></a></li></ul></li></ul></nav></div></div></div></div><div id=head-tags></div><div id=body-inner><h1>Blog 1</h1><h2 id=artificial-intelligencehttpsawsamazoncomblogsmachine-learning><a href=https://aws.amazon.com/blogs/machine-learning/>Artificial Intelligence</a></h2><h1 id=prompting-for-precision-with-stability-ai-image-services-in-amazon-bedrock>Prompting for precision with Stability AI Image Services in Amazon Bedrock</h1><p>by Suleman Patel, Isha Dua, Fabio Branco, and Maxfield Hulker on 18 SEP 2025 in <a href=https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-machine-learning/amazon-bedrock/>Amazon Bedrock</a>, <a href=https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/sagemaker/>Amazon SageMaker</a>, <a href=https://aws.amazon.com/blogs/machine-learning/category/post-types/announcements/>Announcements</a>, <a href=https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/>Artificial Intelligence</a>, <a href=https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/generative-ai/foundation-models/>Foundation models</a>, <a href=https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/generative-ai/>Generative AI</a>, <a href=https://aws.amazon.com/blogs/machine-learning/category/news/launch/>Launch</a> <a href=https://aws.amazon.com/blogs/machine-learning/prompting-for-precision-with-stability-ai-image-services-in-amazon-bedrock/>Permalink</a> <a href=https://aws.amazon.com/blogs/machine-learning/prompting-for-precision-with-stability-ai-image-services-in-amazon-bedrock/#Comments>Comments</a> <a href=https://aws.amazon.com/blogs/machine-learning/prompting-for-precision-with-stability-ai-image-services-in-amazon-bedrock/>Share</a></p><p><a href=https://aws.amazon.com/bedrock/>Amazon Bedrock</a> now offers Stability AI Image Services: 9 tools that improve how businesses create and modify images. The technology extends Stable Diffusion and Stable Image models to give you precise control over image creation and editing. Clear prompts are critical—they provide art direction to the AI system. Strong prompts control specific elements like tone, texture, lighting, and composition to create the desired visual outcomes. This capability serves professional needs across product photography, concept, and marketing campaigns.</p><p>In this post, we expand on the post <a href=https://aws.amazon.com/blogs/machine-learning/understanding-prompt-engineering-unlock-the-creative-potential-of-stability-ai-models-on-aws/>Understanding prompt engineering: Unlock the creative potential of Stability AI models on AWS</a>. We show how to effectively use advanced prompting techniques to maximize image generation quality and precision for enterprise application using Stability AI Image Services in Amazon Bedrock.</p><h2 id=solution-overview><strong>Solution overview</strong></h2><p>Stability AI Image Services are available as APIs in Amazon Bedrock, featuring capabilities such as, in-painting, style transfer, recoloring, background removal, object removal, style guide, and much more.</p><p>In the following sections, we first discuss prompt structure for maximum control of image generation, then we provide advanced techniques of prompting for stylistic guidance. Code samples can be found in the following <a href=https://github.com/aws-samples/stabilityai-sample-notebooks/tree/main/stability-ai-image-services>GitHub repository</a>.</p><h2 id=prerequisites><strong>Prerequisites</strong></h2><p>To get started with Stability AI Image Services in Amazon Bedrock, follow the instructions in <a href=https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started-api.html>Getting started with the API</a> to complete the following prerequisites:</p><ol><li>Set up your AWS account.</li><li>Acquire credentials to grant programmatic access.</li><li>Attach the Amazon Bedrock permission to an <a href=https://aws.amazon.com/iam/>AWS Identity and Access Management</a> (IAM) user or role.</li><li>Request access to the Amazon Bedrock models.</li></ol><h2 id=structure-prompts-that-maximize-control><strong>Structure prompts that maximize control</strong></h2><p>To maximize the granular capabilities of Stability AI Image Services in Amazon Bedrock, you must construct prompts that enable fine-grained control.</p><p>This section outlines best practices for building effective prompts that produce the desired output. We demonstrate how prompt structure affects results and why more structured prompts typically yield more consistent and controllable outcomes.</p><h3 id=choose-the-right-prompt-type-for-your-use-case><strong>Choose the right prompt type for your use case</strong></h3><p>Selecting the right prompt format helps the model better understand your intent. Three primary prompt formats deliver different levels of control and readability:</p><ul><li>Natural language maximizes readability and is best for general usage</li><li>Tag-based formats enable precise structural control and are ideal for technical application</li><li>Hybrid formats combine natural language and the structural elements of tags to provide even more control</li></ul><p>The following table provides examples of these three common ways to phrase your prompts. Each prompt format has its strengths depending on your goal or the interface you’re using.</p><table><thead><tr><th style=text-align:left>Prompt type</th><th style=text-align:left>Prompt example</th><th style=text-align:left>Generated image using Stable Image Ultra in Amazon Bedrock</th><th style=text-align:left>Description and use case</th></tr></thead><tbody><tr><td style=text-align:left>Basic Prompt (Natural Language)</td><td style=text-align:left>“A clean product photo of a perfume bottle on a marble countertop”</td><td style=text-align:left><img alt=" Yourprofile picture" src=https://nguyenleanhquan2005.github.io/AWS_Report/images/image1.png></td><td style=text-align:left>This is readable and intuitive. Great for exploration, conversational tools, and some model types. Stable Diffusion 3.5 responds best to this style.</td></tr><tr><td style=text-align:left>Tag-Based Prompt</td><td style=text-align:left>“perfume bottle, marble surface, soft light, high quality, product photo”</td><td style=text-align:left><img alt=" Yourprofile picture" src=https://nguyenleanhquan2005.github.io/AWS_Report/images/image2.png></td><td style=text-align:left>Used in many generation UIs or with models trained on datasets like LAION or Danbooru. Compact and good for stacking details.</td></tr><tr><td style=text-align:left>Hybrid Prompt</td><td style=text-align:left>“perfume bottle on marble counter, soft studio lighting, sharp focus, f/2.8lens”</td><td style=text-align:left><img alt=" Yourprofile picture" src=https://nguyenleanhquan2005.github.io/AWS_Report/images/image3.png></td><td style=text-align:left>Best of both worlds. Add emphasis with weighting syntax to influence the model’s priorities.</td></tr></tbody></table><h3 id=build-modular-prompts><strong>Build modular prompts</strong></h3><p>Modular prompting enhances AI image generation effectiveness. This approach divides prompts into distinct components, each specifying what to draw and how it should appear. Modular structures provide several benefits: they help prevent conflicting or confusing instructions, allow for precise output control, and simplify prompt debugging. By isolating individual elements, you can quickly identify and adjust effective or ineffective parts of your prompts. This method ultimately leads to more refined and targeted AI-generated images.</p><p>The following table provides examples of modular prompt modules. Experiment with different prompt sequences for your desired outcome; for example, placing the style before the subject will give it a more visual weight.</p><table><thead><tr><th style=text-align:left>Module</th><th style=text-align:left>Example</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left>Prefix</td><td style=text-align:left>“fashion editorial portrait of”</td><td style=text-align:left>Sets the tone and intent for a high-fashion styled portrait</td></tr><tr><td style=text-align:left>Subject</td><td style=text-align:left>“a woman with medium-brown skin and short coiled hair”</td><td style=text-align:left>Gives the model’s look and surface detail to help guide facial features</td></tr><tr><td style=text-align:left>Modifiers</td><td style=text-align:left>“wearing an asymmetrical black mesh top, metallic jewelry”</td><td style=text-align:left>Adds stylized clothing and accessories for visual interest</td></tr><tr><td style=text-align:left>Action</td><td style=text-align:left>“seated with her shoulders angled, eyes locked on camera, one arm lifted”</td><td style=text-align:left>Describes body language and pose to give dynamic composition</td></tr><tr><td style=text-align:left>Environment</td><td style=text-align:left>“bathed in intersecting beams of hard directional light through window slats”</td><td style=text-align:left>Adds context for dramatic light play and atmosphere</td></tr><tr><td style=text-align:left>Style</td><td style=text-align:left>“high-contrast chiaroscuro lighting, sculptural and abstract”</td><td style=text-align:left>Informs the aesthetic and mood (shadow-driven, moody, architectural)</td></tr><tr><td style=text-align:left>Camera/Lighting</td><td style=text-align:left>“shot on 85mm, studio setup, layered shadows and light falling across face and body”</td><td style=text-align:left>Adds technical precision and helps control realism and fidelity</td></tr></tbody></table><p>The following example illustrates how to use a modular prompt to generate the desired output.</p><table><thead><tr><th style=text-align:left>Modular Prompt</th><th style=text-align:left>Generated Image Using Stable Image Ultra in Amazon Bedrock</th></tr></thead><tbody><tr><td style=text-align:left>“fashion editorial portrait of a woman with medium-brown skin and short coiled hair, wearing an asymmetrical black mesh top and metallic jewelry, seated with shoulders angled and one arm lifted, eyes locked on camera, bathed in intersecting beams of hard directional light through window slats, layered shadows and highlights sculpting her face and body, high-contrast chiaroscuro lighting, abstract and bold, shot on 85mm in studio”</td><td style=text-align:left><img alt=" Yourprofile picture" src=https://nguyenleanhquan2005.github.io/AWS_Report/images/image4.png></td></tr></tbody></table><h3 id=use-negative-prompts-for-polished-output><strong>Use negative prompts for polished output</strong></h3><p>prompts improve AI output quality by removing specific visual elements. Explicitly defining what not to include in the prompt guides the model’s output, typically leading to professional outputs. Negative prompts act like a retoucher’s cNegativehecklist used to address aspects of an image to enhance quality and appeal. For example, “No weird hands. No blurry corners. No cartoon filters. Definitely no watermarks.” Negative prompts result in clean, confident, compositions, free of distracting element and distortions.</p><p>The following table provides examples of additional tokens that can be used in negative prompts.</p><table><thead><tr><th style=text-align:left>Artifact Type</th><th style=text-align:left>Tokens to Use</th></tr></thead><tbody><tr><td style=text-align:left>Low quality or noise</td><td style=text-align:left>blurry, lowres, jpeg artifacts, noisy</td></tr><tr><td style=text-align:left>Anatomy or model issues</td><td style=text-align:left>deformed, extra limbs, bad hands, missing fingers</td></tr><tr><td style=text-align:left>Style clashes</td><td style=text-align:left>cartoon, illustration, anime, painting</td></tr><tr><td style=text-align:left>Technical errors</td><td style=text-align:left>watermark, text, signature, overexposed</td></tr><tr><td style=text-align:left>General cleanup</td><td style=text-align:left>ugly, poorly drawn, distortion, worst quality</td></tr></tbody></table><p>The following example illustrates how a well-structured negative prompt can enhance photorealism.</p><table><thead><tr><th style=text-align:left>Without Negative Prompt</th><th style=text-align:left>Prompt <em>“</em>(medium full shot) of (charming office cubicle) made of glass material, multiple colors, modern style, space-saving, upholstered seat, patina, gold trim, located in a modern garden, with sleek furniture, stylish decor, bright lighting, comfortable seating, Masterpiece, best quality, raw photo, realistic, very aesthetic, dark <em>“</em></th><th style=text-align:left><img alt=" Yourprofile picture" src=https://nguyenleanhquan2005.github.io/AWS_Report/images/image5.png></th></tr></thead><tbody><tr><td style=text-align:left>With Negative Prompt</td><td style=text-align:left>Prompt “(medium full shot) of (charming office cubicle) made of glass material, multiple colors, modern style, space-saving, upholstered seat, patina, gold trim, located in a modern garden, with sleek furniture, stylish decor, bright lighting, comfortable seating, Masterpiece, best quality, raw photo, realistic, very aesthetic, dark” Negative Prompt “cartoon, 3d render, cgi, oversaturated, smooth plastic textures, unreal lighting, artificial, matte surface, painterly, dreamy, glossy finish, digital art, low detail background”</td><td style=text-align:left><img alt=" Yourprofile picture" src=https://nguyenleanhquan2005.github.io/AWS_Report/images/image6.png></td></tr></tbody></table><h3 id=emphasize-or-suppress-elements-with-prompt-weighting><strong>Emphasize or suppress elements with prompt weighting</strong></h3><p>Prompt weighting controls the influence of individual elements in AI image generation. These numerical weights prioritize specific prompt components over others. For example, to emphasize the character over the background, you can apply a 1.8 weight to “character” (character: 1.8) and 1.1 to “background” (background: 1.1), which makes sure the model prioritizes character detail while maintaining environmental context. This targeted emphasis produces more precise outputs by minimizing competition between prompt elements and clarifying the model’s priorities.</p><p>The syntax for prompt weights is (&lt;term>:&lt;weight>). You can also use a shorthand such as ((&lt;term>)), where the number of parentheses represent the weight. Values between 0.0–1.0 deemphasize the term, and values between 1.1–2.0 emphasize the term.For example:</p><ul><li>(term:1.2): Emphasize</li><li>(term:0.8): Deemphasize</li><li>((term)): Shorthand for (term:1.2)</li><li>(((((((((term))))))))): Shorthand for (term:1.8)</li></ul><p>The following example shows how prompt weights contribute to the generated output.</p><table><thead><tr><th style=text-align:left>Prompt with weights “editorial product photo of (a translucent gel moisturizer jar:1.4) placed on a (frosted glass pedestal:1.2), surrounded by (dewy pink flower petals:1.1), with soft (diffused lighting:1.3), subtle water droplets, shallow depth of field”</th><th style=text-align:left><img alt=" Yourprofile picture" src=https://nguyenleanhquan2005.github.io/AWS_Report/images/image7.png></th></tr></thead><tbody><tr><td style=text-align:left>Prompt without weights “editorial product photo of a translucent gel moisturizer jar placed on a frosted glass pedestal, surrounded by dewy pink flower petals, with soft, subtle water droplets, shallow depth of field”</td><td style=text-align:left><img alt=" Yourprofile picture" src=https://nguyenleanhquan2005.github.io/AWS_Report/images/image8.png></td></tr></tbody></table><p>You can also use weights in negative prompts to reduce how strongly the model avoids something. For example, “(text:0.5), (blurry:0.2), (lowres:0.1).” This tells the model to be especially sure to avoid generating blurry text or low-resolution content.</p><h2 id=giving-specific-stylistic-guidance><strong>Giving specific stylistic guidance</strong></h2><p>Effective prompt writing when using Stability AI Image Services such as <a href=https://platform.stability.ai/docs/api-reference#tag/Control/paths/~1v2beta~1stable-image~1control~1style-transfer/post>Style Transfer</a> and <a href=https://platform.stability.ai/docs/api-reference#tag/Control/paths/~1v2beta~1stable-image~1control~1style/post>Style Guide</a> requires a good understanding of style matching and reference-driven prompting. These techniques help provide clear stylistic direction for both text-to-image and image-to-image creation.</p><p>Image-to-image style transfer extracts stylistic elements from an input image (control image) and uses it to guide the creation of an output image based on the prompt. Approach writing the prompt as if you’re directing a professional photographer or stylist. Focus on materials, lighting quality, and artistic intention—not just objects. For example, a well-structured prompt might read: “Close-up editorial photo of a translucent green lip gloss tube on crushed iridescent plastic, diffused colored lighting, shallow DOF, high fashion product styling.”</p><h3 id=style-tag-layering-known-aesthetic-labels-that-align-with-brand-identity><strong>Style tag layering: Known aesthetic labels that align with brand identity</strong></h3><p>The art of crafting effective prompts often relies on incorporating established style tags that resonate with familiar visual languages and datasets. By strategically blending terms from recognized aesthetic categories (ranging from editorial photography and analog film to anime, cyberpunk cityscapes, and brutalist structures), creators can guide the AI toward specific visual outcomes that align with their brand identity. These style descriptors serve as powerful anchors in the prompt engineering process. The versatility of these tags extends further through their ability to be combined and weighted, allowing for nuanced control over the final aesthetic. For instance, a skincare brand might blend the clean lines of product photography with dreamy, surreal elements, whereas a tech company could merge brutalist structure with cyberpunk elements for a distinctive visual identity. This approach to style mixing helps creators improve their outputs while maintaining clear ties to recognizable visual genres that resonate with their target audience. The key is understanding how these style tags interact and using their combinations to create unique, yet culturally relevant, visual expressions that serve specific creative or commercial objectives. The following table provides examples of prompts for a desired aesthetic.</p><table><thead><tr><th style=text-align:left>Desired aesthetic</th><th style=text-align:left>Prompt phrases</th><th style=text-align:left>Example use case</th></tr></thead><tbody><tr><td style=text-align:left>Retro / Y2K</td><td style=text-align:left>2000s nostalgia, flash photography, candy tones, harsh lighting</td><td style=text-align:left>Metallic textures, thin fonts, early digital feel.</td></tr><tr><td style=text-align:left>Clean modern</td><td style=text-align:left>neutral tones, soft gradients, minimalist styling, editorial layout</td><td style=text-align:left>Great for wellness or skincare products.</td></tr><tr><td style=text-align:left>Bold streetwear</td><td style=text-align:left>urban background, oversized fit, strong pose, midday shadow</td><td style=text-align:left>Fashion photography and lifestyle ads. Prioritize outfit structure and location cues.</td></tr><tr><td style=text-align:left>Hyperreal surrealism</td><td style=text-align:left>dreamcore lighting, glossy textures, cinematic DOF, surreal shadows</td><td style=text-align:left>Plays well in music, fashion, or alt-culture campaigns.</td></tr></tbody></table><h3 id=invoke-a-named-style-as-a-reference><strong>Invoke a named style as a reference</strong></h3><p>Some prompt structures benefit from invoking a named visual signature from a specific artist, especially when combined with your own stylistic phrasing or workflows, as shown in the following example.</p><table><thead><tr><th style=text-align:left>Prompt “editorial studio portrait of a woman with glowing skin in minimalist glam makeup, high-contrast lighting, clean background, (depiction of Van Gogh style:1.3)”</th><th style=text-align:left><img alt=" Yourprofile picture" src=https://nguyenleanhquan2005.github.io/AWS_Report/images/image9.png></th></tr></thead><tbody></tbody></table><p>The following is a more conceptual example.</p><table><thead><tr><th style=text-align:left>Prompt “product shot of a silver hair oil bottle with soft reflections on curved chrome, (depiction of Wes Anderson style:1.2), under cold studio lighting”</th><th style=text-align:left><img alt=" Yourprofile picture" src=https://nguyenleanhquan2005.github.io/AWS_Report/images/image10.png></th></tr></thead><tbody></tbody></table><p>These phrases function like calling on a genre; they imply choices around materials, lighting, layout, and color tonality.</p><h3 id=use-reference-images-to-guide-style><strong>Use reference images to guide style</strong></h3><p>Another useful technique is using a reference image to guide the pose, color, or composition of the output. For use cases like matching a pose from a lookbook image, transferring a color palette from a campaign still, or copying shadowplay from a photo shoot, you can extract and apply structure or style from reference images.</p><p>Stability AI Image Services support a variety of image-to-image workflows where you can use a reference image (control image) to guide the output, such as <a href=https://platform.stability.ai/docs/api-reference#tag/Control/paths/~1v2beta~1stable-image~1control~1structure/post>Structure</a>, <a href=https://platform.stability.ai/docs/api-reference#tag/Control/paths/~1v2beta~1stable-image~1control~1sketch/post>Sketch</a>, and <a href=https://platform.stability.ai/docs/api-reference#tag/Control/paths/~1v2beta~1stable-image~1control~1style/post>Style</a>. Tools like <a href=https://stability.ai/news/sd3-5-large-controlnets>ControlNet</a> (a neural network architecture developed by Stability AI that enhances control), <a href=https://github.com/tencent-ailab/IP-Adapter>IP-Adapter</a> (an image prompt adapter), or clip-based captioning also enable further control when paired with Stability AI models.</p><p>We will discuss ControlNet, IP-Adapter, and clip-based captioning in a subsequent post.</p><p>The following is an example of an image-to-image workflow:</p><ol><li>Find a high-quality editorial reference.</li><li>Use it with a depth, canny, or seg ControlNet to lock a pose.</li><li>Style with a prompt.</li></ol><table><thead><tr><th style=text-align:left>Prompt “fashion editorial of a model in layered knitwear, dramatic colored lighting, strong shadows, high ISO texture”</th><th style=text-align:left><img alt=" Yourprofile picture" src=https://nguyenleanhquan2005.github.io/AWS_Report/images/image11.png></th></tr></thead><tbody></tbody></table><h3 id=create-the-right-mood-with-lighting-control><strong>Create the right mood with lighting control</strong></h3><p>In a prompt, lighting sets tone, adds dimensionality, and mimics the language of photography. It shouldn’t just be “bright vs. dark.” Lighting is often the style itself, especially for audiences like Gen Z, for instance TikTok, early-aughts flash, harsh backlight, and color gels. The following table provides some useful lighting style prompt terms.</p><table><thead><tr><th style=text-align:left>Lighting style</th><th style=text-align:left>Prompt terms</th><th style=text-align:left>Example use case</th></tr></thead><tbody><tr><td style=text-align:left>High-contrast studio</td><td style=text-align:left>hard directional light, deep shadows, controlled highlights</td><td style=text-align:left>Beauty, tech, fashion with punchy visuals</td></tr><tr><td style=text-align:left>Soft editorial</td><td style=text-align:left>diffused light, soft shadows, ambient glow, overcast</td><td style=text-align:left>Skincare, fashion, wellness</td></tr><tr><td style=text-align:left>Colored gel lighting</td><td style=text-align:left>blue and pink gel lighting, dramatic color shadows, rim lighting</td><td style=text-align:left>Nightlife, music-adjacent fashion, youth-forward styling</td></tr><tr><td style=text-align:left>Natural bounce</td><td style=text-align:left>golden hour, soft natural light, sun flare, warm tones</td><td style=text-align:left>Outdoors, lifestyle, brand-friendly minimalism</td></tr></tbody></table><h3 id=build-intent-with-posing-and-framing-terms><strong>Build intent with posing and framing terms</strong></h3><p>Good posing helps products feel aspirational and digital models more dynamic. With AI, you must be intentional. Framing and pose cues help avoid stiffness, anatomical errors, and randomness. The following table provides some useful posing and framing prompt terms.</p><table><thead><tr><th style=text-align:left>Prompt cue</th><th style=text-align:left>Description</th><th style=text-align:left>Tip</th></tr></thead><tbody><tr><td style=text-align:left>looking off camera</td><td style=text-align:left>Creates candid or editorial energy</td><td style=text-align:left>Useful for lookbooks or ad pages</td></tr><tr><td style=text-align:left>hands in motion</td><td style=text-align:left>Adds realism and fluidity</td><td style=text-align:left>Avoids awkward, static body posture</td></tr><tr><td style=text-align:left>seated with body turned</td><td style=text-align:left>Adds depth and twist to the torso</td><td style=text-align:left>Reduces symmetry, feels natural</td></tr><tr><td style=text-align:left>shot from low angle</td><td style=text-align:left>Power or status cue</td><td style=text-align:left>Works well for stylized streetwear or product hero shots</td></tr></tbody></table><h3 id=example-putting-it-all-together><strong>Example: Putting it all together</strong></h3><p>The following example puts together what we’ve discussed in this post.</p><table><thead><tr><th style=text-align:left>Prompt “studio portrait of a model with platinum hair in metallic cargo pants and a cropped mesh hoodie, seated with legs wide on (acrylic stairs:1.6), magenta and teal gel lighting from left and behind, dramatic contrast, shot on 50mm, streetwear editorial for Gen Z campaign” Negative prompt “blurry, extra limbs, watermark, cartoon, distorted face missing fingers, bad anatomy”</th><th style=text-align:left><img alt=" Yourprofile picture" src=https://nguyenleanhquan2005.github.io/AWS_Report/images/image12.png></th></tr></thead><tbody></tbody></table><p>Let’s break down the preceding prompt. We direct the look of the subject (platinum hair, metallic clothes), specify their pose (seated wide-legged, confident, unposed), define the environment (acrylic stairs and studio setup, controlled, modern), state the lighting (mixed gel sources, bold stylization), designate the lens (50mm, portrait realism), and lastly detail the purpose (for Gen Z campaign, sets visual and cultural tone). Together, the prompt produces the desired result.</p><h2 id=best-practices-and-troubleshooting><strong>Best practices and troubleshooting</strong></h2><p>Prompting is rarely a one-and-done task, especially for creative use cases. Most great images come from refining an idea over multiple attempts. Consider the following methodology to iterate over your prompts:</p><ul><li>Keep a prompt log</li><li>Change one variable at a time</li><li>Save seeds and base images</li><li>Use comparison grids</li></ul><p>Sometimes things go wrong—maybe the model ignores your prompt, or the image looks messy. These issues are common and often quick to fix, and you can get sharper, cleaner, and more intentional outputs with every adjustment. The following table provides useful tips for troubleshooting your prompts.</p><table><thead><tr><th style=text-align:left>Problem</th><th style=text-align:left>Cause of issue</th><th style=text-align:left>How to fix it</th></tr></thead><tbody><tr><td style=text-align:left>Style feels random</td><td style=text-align:left>Model is confused or terms are vague</td><td style=text-align:left>Clarify style, add weight, remove conflicts</td></tr><tr><td style=text-align:left>Face gets warped</td><td style=text-align:left>Over-styled or lacks facial cues</td><td style=text-align:left>Add portrait of, headshot, or adjust pose or lighting</td></tr><tr><td style=text-align:left>Image is too dark</td><td style=text-align:left>Lighting not defined</td><td style=text-align:left>Add softbox from left, natural light, or time of day</td></tr><tr><td style=text-align:left>Repetitive poses</td><td style=text-align:left>Same seed or static structure</td><td style=text-align:left>Switch seed or change camera angle or subject action</td></tr><tr><td style=text-align:left>Lacks realism or feels “AI-ish”</td><td style=text-align:left>Wrong tone or artifacts</td><td style=text-align:left>Add negatives like cartoon, digital texture, distorted</td></tr></tbody></table><h2 id=conclusion><strong>Conclusion</strong></h2><p>Mastering advanced prompting techniques can turn basic image generation into professional creative outputs. Stability AI Image Services in Amazon Bedrock provide precise control over visual creation and editing, helping businesses convert concepts into production-ready assets. The combination of technical expertise and creative intent can help creators achieve the precision and consistency required in professional settings. This control proves valuable across multiple applications, such as marketing campaigns, brand consistency, and product visualizations. This post demonstrated how to optimize Stability AI Image Services in Amazon Bedrock to produce high-quality imagery that aligns with your creative goals.</p><p>To implement these techniques, access Stability AI Image Services through Amazon Bedrock or explore <a href=https://aws.amazon.com/blogs/machine-learning/stability-ai-builds-foundation-models-on-amazon-sagemaker/>Stability AI’s foundation models</a> available in <a href=https://aws.amazon.com/sagemaker/ai/jumpstart/>Amazon SageMaker JumpStart</a>. You can also find practical code examples in our <a href=https://github.com/aws-samples/stabilityai-sample-notebooks/tree/main>GitHub repository</a>.</p><hr><h3 id=about-the-authors><strong>About the authors</strong></h3><p><img alt=" Yourprofile picture" src=https://nguyenleanhquan2005.github.io/AWS_Report/images/image13.png> Maxfield Hulker is the VP of Community and Business Development at Stability AI. He is a longtime leader in the generative AI space. He has helped build creator-focused platforms like Civitai and Dream Studio. Maxfield regularly publishes guides and tutorials to make advanced AI techniques more accessible.</p><p><img alt=" Yourprofile picture" src=https://nguyenleanhquan2005.github.io/AWS_Report/images/image14.jpg> Suleman Patel is a Senior Solutions Architect at Amazon Web Services (AWS), with a special focus on machine learning and modernization. Leveraging his expertise in both business and technology, Suleman helps customers design and build solutions that tackle real-world business problems. When he’s not immersed in his work, Suleman loves exploring the outdoors, taking road trips, and cooking up delicious dishes in the kitchen.</p><p><img alt=" Yourprofile picture" src=https://nguyenleanhquan2005.github.io/AWS_Report/images/image15.png> Isha Dua is a Senior Solutions Architect based in the San Francisco Bay Area working with generative AI model providers and helping customer optimize their generative AI workloads on AWS. She helps enterprise customers grow by understanding their goals and challenges, and guides them on how they can architect their applications in a cloud-based manner while supporting resilience and scalability. She’s passionate about machine learning technologies and environmental sustainability.</p><p><img alt=" Yourprofile picture" src=https://nguyenleanhquan2005.github.io/AWS_Report/images/image16.png> Fabio Branco is a Senior Customer Solutions Manager at Amazon Web Services (AWS) and a strategic advisor, helping customers achieve business transformation, drive innovation through generative AI and data solutions, and successfully navigate their cloud journeys. Prior to AWS, he held Product Management, Engineering, Consulting, and Technology Delivery roles across multiple Fortune 500 companies in industries, including retail and consumer goods, oil and gas, financial services, insurance, and aerospace and defense.</p><footer class=footline></footer></div></div><div id=navigation><a class="nav nav-prev" href=https://nguyenleanhquan2005.github.io/AWS_Report/3-blogstranslated/ title="Translated Blogs"><i class="fa fa-chevron-left"></i></a>
<a class="nav nav-next" href=https://nguyenleanhquan2005.github.io/AWS_Report/3-blogstranslated/3.2-blog2/ title="Blog 2" style=margin-right:0><i class="fa fa-chevron-right"></i></a></div></section><div style=left:-1000px;overflow:scroll;position:absolute;top:-1000px;border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px><div style=border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px></div></div><script src=https://nguyenleanhquan2005.github.io/AWS_Report/js/clipboard.min.js?1765295284></script><script src=https://nguyenleanhquan2005.github.io/AWS_Report/js/perfect-scrollbar.min.js?1765295284></script><script src=https://nguyenleanhquan2005.github.io/AWS_Report/js/perfect-scrollbar.jquery.min.js?1765295284></script><script src=https://nguyenleanhquan2005.github.io/AWS_Report/js/jquery.sticky.js?1765295284></script><script src=https://nguyenleanhquan2005.github.io/AWS_Report/js/featherlight.min.js?1765295284></script><script src=https://nguyenleanhquan2005.github.io/AWS_Report/js/highlight.pack.js?1765295284></script><script>hljs.initHighlightingOnLoad()</script><script src=https://nguyenleanhquan2005.github.io/AWS_Report/js/modernizr.custom-3.6.0.js?1765295284></script><script src=https://nguyenleanhquan2005.github.io/AWS_Report/js/learn.js?1765295284></script><script src=https://nguyenleanhquan2005.github.io/AWS_Report/js/hugo-learn.js?1765295284></script><link href=https://nguyenleanhquan2005.github.io/AWS_Report/mermaid/mermaid.css?1765295284 rel=stylesheet><script src=https://nguyenleanhquan2005.github.io/AWS_Report/mermaid/mermaid.js?1765295284></script><script>mermaid.initialize({startOnLoad:!0})</script><script>(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,(e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date),(i=t.createElement(n),a=t.getElementsByTagName(n)[0]),i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-158079754-2","auto"),ga("send","pageview")</script></body></html>